
#-----------
train_generator = ImageDataGenerator(rescale=1./255,validation_split=0.0).flow_from_dataframe(dataframe=dataframe, directory='/mnt/CommonDrive/Pyqt/CIFAR10/train', x_col='id', y_col='label', class_mode='categorical', target_size=(28, 28), batch_size=3,has_ext=False)
x1=Input(shape=(28,28,3,))
x3=Flatten()(x1)
x4=Dense(10, activation=None)(x3)
x2=(x4)
model = Model(inputs=x1, outputs=x2)
model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.001, clipvalue=0.001), metrics=['accuracy'])
model.fit_generator(self.train_gen, steps_per_epoch=15,epochs =15,callbacks=[self.hist])

#-----------
train_generator = ImageDataGenerator(rescale=1./255,validation_split=0.2).flow_from_directory('/mnt/CommonDrive/Pyqt/MNIST/trainingSet',target_size=(28, 28),batch_size=3,class_mode='categorical')
x1=Input(shape=(28,28,3,))
x5=Conv2D(4,kernel_size=3,strides=1, padding='same',activation=None)(x1)
x6=MaxPool2D()(x5)
x9=BatchNormalization()(x6)
x3=Conv2D(4,kernel_size=3,strides=1, padding='same',activation=None)(x1)
x4=MaxPool2D()(x3)
x10=BatchNormalization()(x4)
x7=Conv2D(4,kernel_size=3,strides=1, padding='same',activation=None)(x10)
x8=BatchNormalization()(x7)
x11=Add()([x8,x9])
x12=Flatten()(x11)
x13=Dense(10, activation=None)(x12)
x14=Activation('softmax')(x13)
x2=(x14)
model = Model(inputs=x1, outputs=x2)
model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.001, clipvalue=1.0), metrics=['accuracy'])

#-----------
train_generator = ImageDataGenerator(rescale=1./255,validation_split=0.2).flow_from_directory('/mnt/CommonDrive/Pyqt/MNIST/trainingSet',target_size=(28, 28),batch_size=5,class_mode='categorical')
x1=Input(shape=(28,28,3,))
x4=Conv2D(4,kernel_size=3,strides=1, padding='same',activation=None)(x1)
x9=MaxPool2D()(x4)
x6=BatchNormalization()(x9)
x5=Conv2D(4,kernel_size=3,strides=1, padding='same',activation=None)(x1)
x10=MaxPool2D()(x5)
x8=BatchNormalization()(x10)
x3=Conv2D(4,kernel_size=3,strides=1, padding='same',activation=None)(x8)
x7=BatchNormalization()(x3)
x11=Add()([x7,x6])
x12=Flatten()(x11)
x13=Dense(10, activation=None)(x12)
x14=Activation('softmax')(x13)
x2=(x14)
model = Model(inputs=x1, outputs=x2)
model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.001, clipvalue=1.0), metrics=['accuracy'])
model.fit_generator(self.train_gen, steps_per_epoch=20,epochs =20,callbacks=[self.hist])

#-----------
train_generator = ImageDataGenerator(rescale=1./255,validation_split=0.2).flow_from_directory('/mnt/CommonDrive/Pyqt/MNIST/trainingSet',target_size=(28, 28),batch_size=5,class_mode='categorical')
x15=Input(shape=(28,28,3,))
x1=Input(shape=(28,28,3,))
x16=Add()([x15,x1])
x17=Conv2D(4,kernel_size=3,strides=1, padding='same',activation=None)(x16)
x18=MaxPool2D()(x17)
x19=BatchNormalization()(x18)
x4=Conv2D(4,kernel_size=3,strides=1, padding='same',activation=None)(x1)
x9=MaxPool2D()(x4)
x6=BatchNormalization()(x9)
x5=Conv2D(4,kernel_size=3,strides=1, padding='same',activation=None)(x1)
x10=MaxPool2D()(x5)
x8=BatchNormalization()(x10)
x3=Conv2D(4,kernel_size=3,strides=1, padding='same',activation=None)(x8)
x7=BatchNormalization()(x3)
x11=Add()([x7,x6,x19])
x12=Flatten()(x11)
x13=Dense(10, activation=None)(x12)
x22=Dense(10, activation=None)(x13)
x21=Dense(10, activation=None)(x22)
x23=(x21)
x14=Activation('softmax')(x13)
x20=Dense(10, activation=None)(x14)
x24=(x20)
x2=(x14)
model = Model(inputs=[x1,x15], outputs=[x2,x23,x24])
model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.001, clipvalue=1.0), metrics=['accuracy'])
model.fit_generator(self.train_gen, steps_per_epoch=20,epochs =20,callbacks=[self.hist])

#-----------
train_generator = ImageDataGenerator(rescale=1./255,validation_split=0.2).flow_from_directory('/mnt/CommonDrive/Pyqt/trainingSet',target_size=(28, 28),batch_size=3,class_mode='categorical')
x1=Input(shape=(28,28,3,))
x3=Conv2D(2,kernel_size=3,strides=1, padding='same',activation=None)(x1)
x4=MaxPool2D()(x3)
x5=Flatten()(x4)
x6=Dropout(0.5)(x5)
x8=Dense(10, activation=None)(x6)
x7=Activation('softmax')(x8)
x2=(x7)
model = Model(inputs=x1, outputs=x2)
model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(lr=0.001, clipvalue=1.0), metrics=['accuracy'])
model.fit_generator(self.train_gen, steps_per_epoch=15,epochs =20,callbacks=[self.hist,self.customTensBordCall])
